statTable <- function(x)
{
statistics <- cbind(mfv(x), mean(x), var(x), sd(x), t(quantile(x)))
return(statistics)
}
estadisticas <- apply(data[,c("sat", "tothrs", "hsize", "hsrank")],2,statTable)
rownames(estadisticas) <- c("moda", "media", "var", "desv.est", "min", "Q1", "Q2", "Q3", "max")
install.packages("printr", type = "source",
repos=c("http://yihui.name/xran"))
library(printr)
estadisticas
detach("package:printr", unload = TRUE)
hist(sat, main="Histograma de la nota de acceso",col="blue", xlim = c(600,1400))
ggplot(data =  data, aes(x=sat, fill=female)) +
geom_histogram(bins = 30) +
scale_fill_manual(values = c("orange", "blue"),
labels = c("Men", "Women"),
name = "Sex") +
ggtitle('sat en funciÃ³n del sexo') +
theme(plot.title = element_text(hjust = 0.5))
write.csv(data, file = "gpa_clean.csv" ,row.names = FALSE)
version
update.packages()
install.packages("DescTools", type="binary")
install.packages("DescTools", type="binary")
library(DescTools)
tinytex::reinstall_tinytex(repository = "illinois")
if(!require(RCurl)){
install.packages('RCurl',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(RCurl)
}
if(!require(data.table)){
install.packages('data.table',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(data.table)
}
if(!require(tidyr)){
install.packages('tidyr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(tidyr)
}
if(!require(ggplot2)){
install.packages('ggplot2',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(ggplot2)
}
if(!require(stringr)){
install.packages('stringr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(stringr)
}
if(!require(funModeling)){
install.packages('funModeling',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(funModeling)
}
if(!require(Hmisc)){install.packages('Hmisc',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(Hmisc)
}
if(!require(plyr)){install.packages('plyr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(plyr)
}
if(!require(car)){install.packages('car',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(car)
}
if(!require(ggpubr)){install.packages('ggpubr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(ggpubr)
}
if(!require(lsr)){install.packages('lsr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(lsr)
}
if(!require(DescTools)){install.packages('DescTools',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(DescTools)
}
if(!require(gridExtra)){
install.packages('gridextra',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(gridExtra)
}
if(!require(caret)){
install.packages('caret',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(caret)
}
if(!require(RCurl)){
install.packages('RCurl',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(RCurl)
}
if(!require(data.table)){
install.packages('data.table',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(data.table)
}
if(!require(tidyr)){
install.packages('tidyr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(tidyr)
}
if(!require(ggplot2)){
install.packages('ggplot2',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(ggplot2)
}
if(!require(stringr)){
install.packages('stringr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(stringr)
}
if(!require(funModeling)){
install.packages('funModeling',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(funModeling)
}
if(!require(Hmisc)){install.packages('Hmisc',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(Hmisc)
}
if(!require(plyr)){install.packages('plyr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(plyr)
}
if(!require(car)){install.packages('car',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(car)
}
if(!require(ggpubr)){install.packages('ggpubr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(ggpubr)
}
if(!require(lsr)){install.packages('lsr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(lsr)
}
if(!require(DescTools)){install.packages('DescTools',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(DescTools)
}
if(!require(gridExtra)){
install.packages('gridextra',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(gridExtra)
}
if(!require(caret)){
install.packages('caret',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(caret)
}
if(!require(RCurl)){
install.packages('RCurl',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(RCurl)
}
if(!require(data.table)){
install.packages('data.table',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(data.table)
}
if(!require(tidyr)){
install.packages('tidyr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(tidyr)
}
if(!require(ggplot2)){
install.packages('ggplot2',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(ggplot2)
}
if(!require(stringr)){
install.packages('stringr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(stringr)
}
if(!require(funModeling)){
install.packages('funModeling',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(funModeling)
}
if(!require(Hmisc)){install.packages('Hmisc',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(Hmisc)
}
if(!require(plyr)){install.packages('plyr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(plyr)
}
if(!require(car)){install.packages('car',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(car)
}
if(!require(ggpubr)){install.packages('ggpubr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(ggpubr)
}
if(!require(lsr)){install.packages('lsr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(lsr)
}
if(!require(DescTools)){install.packages('DescTools',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(DescTools)
}
if(!require(gridExtra)){
install.packages('gridextra',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(gridExtra)
}
if(!require(caret)){
install.packages('caret',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(caret)
}
if(!require(RCurl)){
install.packages('RCurl',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(RCurl)
}
if(!require(data.table)){
install.packages('data.table',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(data.table)
}
if(!require(tidyr)){
install.packages('tidyr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(tidyr)
}
if(!require(ggplot2)){
install.packages('ggplot2',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(ggplot2)
}
if(!require(stringr)){
install.packages('stringr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(stringr)
}
if(!require(funModeling)){
install.packages('funModeling',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(funModeling)
}
if(!require(Hmisc)){install.packages('Hmisc',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(Hmisc)
}
if(!require(plyr)){install.packages('plyr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(plyr)
}
if(!require(car)){install.packages('car',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(car)
}
if(!require(ggpubr)){install.packages('ggpubr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(ggpubr)
}
if(!require(lsr)){install.packages('lsr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(lsr)
}
if(!require(DescTools)){install.packages('DescTools',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(DescTools)
}
if(!require(gridExtra)){
install.packages('gridextra',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(gridExtra)
}
if(!require(caret)){
install.packages('caret',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(caret)
}
.libPaths()
print("Hello")
setwd("C:/Machine Learning/machinelearning-az/datasets/Part 7 - Natural Language Processing/Section 36 - Natural Language Processing")
# TAREA
# Importar el dataset
dataset_original <- read.csv('Restaurant_Reviews.tsv',
quote = '', # Cualquier cosa puede ser un texto
stringsAsFactors = FALSE, # Para que no transforme los textos a factor
sep = '\t')
# Limpieza de texto
#install.packages("tm")
#install.packages("SnowballC")
library(tm)
library(SnowballC)
corpus = VCorpus(VectorSource(dataset_original$Review))
corpus = tm_map(corpus, content_transformer(tolower))
corpus = tm_map(corpus, removeNumbers)
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, stopwords(kind = 'en'))
corpus = tm_map(corpus, stemDocument)
corpus = tm_map(corpus, stripWhitespace)
# Crear el modelo Bag of Words
dtm = DocumentTermMatrix(corpus)
dtm = removeSparseTerms(dtm, 0.999) # 99.9% de palabras mÃ¡s frecuentes
dataset = as.data.frame(as.matrix(dtm))
dataset$Liked = dataset_original$Liked
dataset$Liked <- factor(dataset$Liked,
levels = c(0, 1))
# Dividir los datos en training y testing
#install.packages("caTools")
library(caTools)
set.seed(123)
split <- sample.split(dataset$Liked, SplitRatio = 0.8)
training_set = subset(dataset, split == TRUE)
testing_set = subset(dataset, split == FALSE)
# PREGUNTA 1
# Ajustar los clasificadores en el Conjunto de Entrenamiento
library("randomForest")
library("class")
library("e1071")
nb = naiveBayes(x = training_set[,-3],
y = training_set$Purchased)
nb = naiveBayes(x = training_set[,-3],
y = training_set$Purchased)
View(training_set)
nb = naiveBayes(x = training_set[,-ncol(dataset)],
y = training_set$Liked)
nb = naiveBayes(x = training_set[,-ncol(dataset)],
y = training_set$Liked)
lr = glm(x = training_set[,-ncol(dataset)],
y = training_set$Liked,
family = binomial)
nb = naiveBayes(x = training_set[,-ncol(dataset)],
y = training_set$Liked)
lr = glm(x = training_set[,-ncol(dataset)],
y = training_set$Liked,
family = binomial)
View(dataset)
nb = naiveBayes(x = training_set[,-ncol(dataset)],
y = training_set$Liked)
lr = glm(formula = Liked ~ .,
data = training_set,
family = binomial)
knn = knn(train = training_set[,-ncol(dataset)],
test = testing_set[,-ncol(dataset)],
cl = training_set$Liked,
k = 5)
svc = svm(formula = Liked ~ .,
data = training_set,
type = "C-classification",
kernel = "linear")
tc = rpart(formula = Liked ~ .,
data = training_set)
library("rpart")
tc = rpart(formula = Liked ~ .,
data = training_set)
rfc = randomForest(x = training_set[,-ncol(dataset)],
y = training_set$Liked,
ntree = 10)
models_list = c(nb, lr, knn, svc, svc_nl, tc, rfc)
svc_nl = Ssvm(formula = Purchased ~ .,
data = training_set,
type = "C-classification",
kernel = "radial")
svc_nl = svm(formula = Purchased ~ .,
data = training_set,
type = "C-classification",
kernel = "radial")
models_list = c(nb, lr, knn, svc, svc_nl, tc, rfc)
svc_nl = svm(formula = Liked ~ .,
data = training_set,
type = "C-classification",
kernel = "radial")
models_list = c(nb, lr, knn, svc, svc_nl, tc, rfc)
# Importar el dataset
dataset_original <- read.csv('Restaurant_Reviews.tsv',
quote = '', # Cualquier cosa puede ser un texto
stringsAsFactors = FALSE, # Para que no transforme los textos a factor
sep = '\t')
# Importar el dataset
dataset_original <- read.csv('Restaurant_Reviews.tsv',
quote = '', # Cualquier cosa puede ser un texto
stringsAsFactors = FALSE, # Para que no transforme los textos a factor
sep = '\t')
# Limpieza de texto
#install.packages("tm")
#install.packages("SnowballC")
library(tm)
library(SnowballC)
corpus = VCorpus(VectorSource(dataset_original$Review))
corpus = tm_map(corpus, content_transformer(tolower))
corpus = tm_map(corpus, removeNumbers)
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, stopwords(kind = 'en'))
corpus = tm_map(corpus, stemDocument)
corpus = tm_map(corpus, stripWhitespace)
# Crear el modelo Bag of Words
dtm = DocumentTermMatrix(corpus)
dtm = removeSparseTerms(dtm, 0.999) # 99.9% de palabras mÃ¡s frecuentes
dataset = as.data.frame(as.matrix(dtm))
dataset$Liked = dataset_original$Liked
dataset$Liked <- factor(dataset$Liked,
levels = c(0, 1))
# Dividir los datos en training y testing
#install.packages("caTools")
library(caTools)
set.seed(123)
split <- sample.split(dataset$Liked, SplitRatio = 0.8)
training_set = subset(dataset, split == TRUE)
testing_set = subset(dataset, split == FALSE)
# PREGUNTA 1
# Ajustar los clasificadores en el Conjunto de Entrenamiento
library("randomForest")
library("class")
library("e1071")
library("rpart")
nb = naiveBayes(x = training_set[,-ncol(dataset)],
y = training_set$Liked)
lr = glm(formula = Liked ~ .,
data = training_set,
family = binomial)
knn = knn(train = training_set[,-ncol(dataset)],
test = testing_set[,-ncol(dataset)],
cl = training_set$Liked,
k = 5)
svc = svm(formula = Liked ~ .,
data = training_set,
type = "C-classification",
kernel = "linear")
svc_nl = svm(formula = Liked ~ .,
data = training_set,
type = "C-classification",
kernel = "radial")
tc = rpart(formula = Liked ~ .,
data = training_set)
rfc = randomForest(x = training_set[,-ncol(dataset)],
y = training_set$Liked,
ntree = 10)
models_list = c(nb, lr, knn, svc, svc_nl, tc, rfc)
models_names = c("Naive Bayes", "Logistic Regression",
"k-nearest neighbors", "SVC",
"SVC Non Linear", 'Tree Classifier',
"Random Forest Classifier")
# PREGUNTA 2
# PredicciÃ³n de los resulados con el Conjunto de Testing
accuracy_list = numeric()
precision_list = numeric()
recall_list = numeric()
f1_list = numeric()
for (i in seq_along(models_list)) {
y_pred = predict(models_list[i], newdata = testing_set[,-ncol(dataset)])
cm = table(testing_set[,ncol(dataset)], y_pred)
print(models_names[i])
print(cm)
accuracy = (cm[1][1] + cm[0][0]) / (cm[0][0] + cm[1][1] + cm[0][1] + cm[1][0])
precision = cm[1][1] / (cm[1][1] + cm[0][1])
recall = cm[1][1] / (cm[1][1] + cm[1][0])
f1_s = 2*precision*recall / (precision + recall)
accuracy_list <- c(accuracy_list, accuracy)
precision_list <- c(precision_list, precision)
recall_list <- c(recall_list, recall)
f1_list <- c(f1_list, f1_s)
}
y_pred = predict(rfc, newdata = testing_set[,-ncol(dataset)])
y_pred
y_pred = predict(models_list[1], newdata = testing_set[,-ncol(dataset)])
models_list = c(nb, lr, knn, svc, svc_nl, tc, randomForest(x = training_set[,-ncol(dataset)], y = training_set$Liked, ntree = 10))
models_list = c(nb, lr, knn, svc, svc_nl, tc, randomForest(x = training_set[,-ncol(dataset)], y = training_set$Liked, ntree = 10))
models_names = c("Naive Bayes", "Logistic Regression",
"k-nearest neighbors", "SVC",
"SVC Non Linear", 'Tree Classifier',
"Random Forest Classifier")
y_pred = predict(models_list[1], newdata = testing_set[,-ncol(dataset)])
y_pred = predict(models_list[7], newdata = testing_set[,-ncol(dataset)])
models_names[7]
models_list[1]
rfc
models_list = list(nb, lr, knn, svc, svc_nl, tc, randomForest(x = training_set[,-ncol(dataset)], y = training_set$Liked, ntree = 10))
models_list[1]
models_list[2]
models_list[7]
y_pred = predict(models_list[7], newdata = testing_set[,-ncol(dataset)])
df = data.frame(models_names[1] = numeric(0), models_names[2] = numeric(0),
df = data.frame("models_names[1]" = numeric(0));
View(df)
metricas = data.frame("Naive Bayes" = numeric(0), "Logistic Regression" = numeric(0),
"k-nearest neighbors" = numeric(0), "SVC" = numeric(0),
"SVC Non Linear" = numeric(0), 'Tree Classifier' = numeric(0),
"Random Forest Classifier" = numeric(0));
View(metricas)
metricas$no = 1
metricas = data.frame("Naive Bayes" = numeric(7), "Logistic Regression" = numeric(7),
"k-nearest neighbors" = numeric(7), "SVC" = numeric(7),
"SVC Non Linear" = numeric(7), 'Tree Classifier' = numeric(7),
"Random Forest Classifier" = numeric(7));
View(metricas)
metricas = data.frame("Naive Bayes" = numeric(length(models_names)), "Logistic Regression" = numeric(7),
"k-nearest neighbors" = numeric(7), "SVC" = numeric(7),
"SVC Non Linear" = numeric(7), 'Tree Classifier' = numeric(7),
"Random Forest Classifier" = numeric(7));
metricas = data.frame("Naive Bayes" = numeric(length(models_names)), "Logistic Regression" = numeric(length(models_names)),
"k-nearest neighbors" = numeric(length(models_names)), "SVC" = numeric(length(models_names)),
"SVC Non Linear" = numeric(length(models_names)), 'Tree Classifier' = numeric(length(models_names)),
"Random Forest Classifier" = numeric(length(models_names)));
metricas = data.frame("Naive Bayes" = numeric(4), "Logistic Regression" = numeric(4),
"k-nearest neighbors" = numeric(4), "SVC" = numeric(4),
"SVC Non Linear" = numeric(4), 'Tree Classifier' = numeric(4),
"Random Forest Classifier" = numeric(4));
View(metricas)
metricas$Naive.Bayes <- c(1,2,3,9)
View(metricas)
y_pred = c(y_pred_nb, y_pred_lr, y_pred_knn, y_pred_svc, y_pred_svc_nl, y_pred_tc, y_pred_rfc)
y_pred_nb = predict(nb, newdata = testing_set[,-ncol(dataset)])
y_pred = c(y_pred_nb, y_pred_lr, y_pred_knn, y_pred_svc, y_pred_svc_nl, y_pred_tc, y_pred_rfc)
nb = naiveBayes(x = training_set[,-ncol(dataset)],
y = training_set$Liked)
y_pred_nb = predict(nb, newdata = testing_set[,-ncol(dataset)])
lr = glm(formula = Liked ~ .,
data = training_set,
family = binomial)
y_pred_lr = predict(lr, newdata = testing_set[,-ncol(dataset)])
knn = knn(train = training_set[,-ncol(dataset)],
test = testing_set[,-ncol(dataset)],
cl = training_set$Liked,
k = 5)
y_pred_knn = predict(knn, newdata = testing_set[,-ncol(dataset)])
nb = naiveBayes(x = training_set[,-ncol(dataset)],
y = training_set$Liked)
y_pred_nb = predict(nb, newdata = testing_set[,-ncol(dataset)])
lr = glm(formula = Liked ~ .,
data = training_set,
family = binomial)
y_pred_lr = predict(lr, newdata = testing_set[,-ncol(dataset)])
knn = knn(train = training_set[,-ncol(dataset)],
test = testing_set[,-ncol(dataset)],
cl = training_set$Liked,
k = 5)
y_pred_knn = predict(knn, newdata = testing_set[,-ncol(dataset)])
y_pred_knn = knn(train = training_set[,-ncol(dataset)],
test = testing_set[,-ncol(dataset)],
cl = training_set$Liked,
k = 5)
svc = svm(formula = Liked ~ .,
data = training_set,
type = "C-classification",
kernel = "linear")
y_pred_svc = predict(svc, newdata = testing_set[,-ncol(dataset)])
svc_nl = svm(formula = Liked ~ .,
data = training_set,
type = "C-classification",
kernel = "radial")
y_pred_svc_nl = predict(svc_nl, newdata = testing_set[,-ncol(dataset)])
tc = rpart(formula = Liked ~ .,
data = training_set)
y_pred_tc = predict(tc, newdata = testing_set[,-ncol(dataset)])
rfc = randomForest(x = training_set[,-ncol(dataset)],
y = training_set$Liked,
ntree = 10)
y_pred_rfc = predict(rfc, newdata = testing_set[,-ncol(dataset)])
models_names = c("Naive Bayes", "Logistic Regression",
"k-nearest neighbors", "SVC",
"SVC Non Linear", 'Tree Classifier',
"Random Forest Classifier")
y_pred = c(y_pred_nb, y_pred_lr, y_pred_knn, y_pred_svc, y_pred_svc_nl, y_pred_tc, y_pred_rfc)
y_pred
