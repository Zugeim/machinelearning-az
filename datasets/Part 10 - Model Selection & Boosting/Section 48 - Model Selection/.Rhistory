head(colgpa)
summary(colgpa)
class(hsize)
head(hsize, 3)
grep(",", hsize)
hsize <- gsub(",",".",hsize)
grep(",",hsize)
hsize <- as.numeric(hsize)
data$hsize <- hsize
summary(hsize)
class(hsperc)
head(hsperc, 3)
summary(hsperc)
class(hsrank)
head(hsrank, 3)
summary(hsrank)
hsrank <- as.numeric(hsrank)
data$hsrank <- hsrank
class(data$hsrank)
summary(data$hsrank)
hsperc <- round(hsperc, 3)
data$hsperc <- hsperc
aux <- data[!is.na(hsize) & (round(hsrank/hsize, 3) != hsperc), c("hsrank", "hsize", "hsperc")]
data[!is.na(hsize) & (round(hsrank/hsize, 3) != hsperc), c("hsperc")] <- round((aux$hsrank/aux$hsize), 3)
hsperc <- data$hsperc
# Comprobación de si hay números mal.
sum(data[!is.na(hsize) & (round(hsrank/hsize, 3) != hsperc), c("hsize", "hsrank", "hsperc")])
head(data[,c("hsize", "hsrank", "hsperc")])
if(!require(ggplot2)){
install.packages('ggplot2',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(ggplot2)
}
ggplot(mapping = aes(x=sat))+ geom_density()
ggplot(mapping = aes(x=hsize))+ geom_density()
boxplot(sat, main = "sat")
boxplot(hsize, main = "hsize")
boxplot.stats(sat)$out -> outlier_values
li <- boxplot.stats(sat)$stats[1]
ls <- boxplot.stats(sat)$stats[5]
sat[sat > ls | sat < li] <- NA
data$sat <- sat
boxplot(data$sat, main = "sat")
boxplot.stats(hsize)$out -> outlier_values
ls <- boxplot.stats(hsize)$stats[5]
hsize[hsize > ls] <- NA
data$hsize <- hsize
boxplot(data$hsize, main = "hsize")
boxplot.stats(hsize)$out -> outlier_values
ls <- boxplot.stats(hsize)$stats[5]
hsize[hsize > ls] <- NA
data$hsize <- hsize
boxplot(data$hsize, main = "hsize")
boxplot.stats(hsize)$out -> outlier_values
ls <- boxplot.stats(hsize)$stats[5]
hsize[hsize > ls] <- NA
data$hsize <- hsize
boxplot(data$hsize, main = "hsize")
summary(data)
if(!require(VIM)){
install.packages('VIM',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(VIM)
}
library(VIM)
data <- kNN(data, k = 11)
data[data$hsize_imp == TRUE |
data$sat_imp == TRUE |
data$colgpa_imp == TRUE,c(1,2,3,4,5,6)]
summary(data[,c("sat", "hsize", "colgpa")])
sat <- data[,c("sat")]
hsize <- data[,c("hsize")]
colgpa <- data[,c("colgpa")]
gpaletter <- cut(colgpa, breaks = c(0, 1.5, 2.50, 3.5, 4), labels = c("D", "C", "B", "A"), include.lowest = TRUE, right = FALSE)
unique(gpaletter[colgpa < 1.50])
unique(gpaletter[colgpa >= 1.5 & colgpa < 2.5])
unique(gpaletter[colgpa >= 2.5 & colgpa < 3.5])
unique(gpaletter[colgpa >= 3.5 & colgpa <= 4])
data$gpaletter <- gpaletter
head(data[,c("gpaletter", "colgpa")])
barplot(prop.table(table(athlete)),
main = "Athletes",
col = c("orange", "blue"),
ylim= c(0,1),
ylab = "percentage of athletes")
ggplot(data =  data, aes(x=athlete, fill=female)) +
geom_bar(position = "fill") +
scale_fill_manual(values = c("orange", "blue"),
labels = c("Men", "Women"),
name = "Sex") +
ggtitle('Athletes en función del sexo') +
theme(panel.background = element_rect(fill = "transparent"),
plot.title = element_text(hjust = 0.5)) +
labs(y="percentage of men and women")
if(!require(modeest)){
install.packages('modeest',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(modeest)
}
library(modeest)
statTable <- function(x)
{
statistics <- cbind(mfv(x), mean(x), var(x), sd(x), t(quantile(x)))
return(statistics)
}
estadisticas <- apply(data[,c("sat", "tothrs", "hsize", "hsrank")],2,statTable)
rownames(estadisticas) <- c("moda", "media", "var", "desv.est", "min", "Q1", "Q2", "Q3", "max")
install.packages("printr", type = "source",
repos=c("http://yihui.name/xran"))
library(printr)
estadisticas
detach("package:printr", unload = TRUE)
hist(sat, main="Histograma de la nota de acceso",col="blue", xlim = c(600,1400))
ggplot(data =  data, aes(x=sat, fill=female)) +
geom_histogram(bins = 30) +
scale_fill_manual(values = c("orange", "blue"),
labels = c("Men", "Women"),
name = "Sex") +
ggtitle('sat en función del sexo') +
theme(plot.title = element_text(hjust = 0.5))
write.csv(data, file = "gpa_clean.csv" ,row.names = FALSE)
version
update.packages()
install.packages("DescTools", type="binary")
install.packages("DescTools", type="binary")
library(DescTools)
tinytex::reinstall_tinytex(repository = "illinois")
if(!require(RCurl)){
install.packages('RCurl',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(RCurl)
}
if(!require(data.table)){
install.packages('data.table',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(data.table)
}
if(!require(tidyr)){
install.packages('tidyr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(tidyr)
}
if(!require(ggplot2)){
install.packages('ggplot2',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(ggplot2)
}
if(!require(stringr)){
install.packages('stringr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(stringr)
}
if(!require(funModeling)){
install.packages('funModeling',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(funModeling)
}
if(!require(Hmisc)){install.packages('Hmisc',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(Hmisc)
}
if(!require(plyr)){install.packages('plyr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(plyr)
}
if(!require(car)){install.packages('car',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(car)
}
if(!require(ggpubr)){install.packages('ggpubr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(ggpubr)
}
if(!require(lsr)){install.packages('lsr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(lsr)
}
if(!require(DescTools)){install.packages('DescTools',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(DescTools)
}
if(!require(gridExtra)){
install.packages('gridextra',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(gridExtra)
}
if(!require(caret)){
install.packages('caret',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(caret)
}
if(!require(RCurl)){
install.packages('RCurl',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(RCurl)
}
if(!require(data.table)){
install.packages('data.table',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(data.table)
}
if(!require(tidyr)){
install.packages('tidyr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(tidyr)
}
if(!require(ggplot2)){
install.packages('ggplot2',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(ggplot2)
}
if(!require(stringr)){
install.packages('stringr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(stringr)
}
if(!require(funModeling)){
install.packages('funModeling',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(funModeling)
}
if(!require(Hmisc)){install.packages('Hmisc',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(Hmisc)
}
if(!require(plyr)){install.packages('plyr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(plyr)
}
if(!require(car)){install.packages('car',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(car)
}
if(!require(ggpubr)){install.packages('ggpubr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(ggpubr)
}
if(!require(lsr)){install.packages('lsr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(lsr)
}
if(!require(DescTools)){install.packages('DescTools',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(DescTools)
}
if(!require(gridExtra)){
install.packages('gridextra',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(gridExtra)
}
if(!require(caret)){
install.packages('caret',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(caret)
}
if(!require(RCurl)){
install.packages('RCurl',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(RCurl)
}
if(!require(data.table)){
install.packages('data.table',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(data.table)
}
if(!require(tidyr)){
install.packages('tidyr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(tidyr)
}
if(!require(ggplot2)){
install.packages('ggplot2',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(ggplot2)
}
if(!require(stringr)){
install.packages('stringr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(stringr)
}
if(!require(funModeling)){
install.packages('funModeling',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(funModeling)
}
if(!require(Hmisc)){install.packages('Hmisc',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(Hmisc)
}
if(!require(plyr)){install.packages('plyr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(plyr)
}
if(!require(car)){install.packages('car',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(car)
}
if(!require(ggpubr)){install.packages('ggpubr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(ggpubr)
}
if(!require(lsr)){install.packages('lsr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(lsr)
}
if(!require(DescTools)){install.packages('DescTools',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(DescTools)
}
if(!require(gridExtra)){
install.packages('gridextra',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(gridExtra)
}
if(!require(caret)){
install.packages('caret',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(caret)
}
if(!require(RCurl)){
install.packages('RCurl',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(RCurl)
}
if(!require(data.table)){
install.packages('data.table',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(data.table)
}
if(!require(tidyr)){
install.packages('tidyr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(tidyr)
}
if(!require(ggplot2)){
install.packages('ggplot2',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(ggplot2)
}
if(!require(stringr)){
install.packages('stringr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(stringr)
}
if(!require(funModeling)){
install.packages('funModeling',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(funModeling)
}
if(!require(Hmisc)){install.packages('Hmisc',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(Hmisc)
}
if(!require(plyr)){install.packages('plyr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(plyr)
}
if(!require(car)){install.packages('car',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(car)
}
if(!require(ggpubr)){install.packages('ggpubr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(ggpubr)
}
if(!require(lsr)){install.packages('lsr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(lsr)
}
if(!require(DescTools)){install.packages('DescTools',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(DescTools)
}
if(!require(gridExtra)){
install.packages('gridextra',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(gridExtra)
}
if(!require(caret)){
install.packages('caret',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(caret)
}
.libPaths()
print("Hello")
setwd("C:/Machine Learning/machinelearning-az/datasets/Part 10 - Model Selection & Boosting/Section 48 - Model Selection")
# Aplicar el algoritmo de k-fold cross validation ++++++++++++++++++++++++++++++
library(caret)
dataset <- read.csv('Social_Network_Ads.csv')
dataset <- dataset[, 3:5]
# K-FOLD CROSS VALIDATION
# Importar el dataset
dataset <- read.csv('Social_Network_Ads.csv')
dataset <- dataset[, 3:5]
# Dividir los datos en training y testing
#install.packages("caTools")
library(caTools)
set.seed(123)
split <- sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
testing_set = subset(dataset, split == FALSE)
# Escalado de variables
training_set[,1:2] = scale(training_set[,1:2])
testing_set[,1:2] = scale(testing_set[,1:2])
# Ajustar el clasificador en el Conjunto de Entrenamiento
library(e1071)
classifier = svm(formula = Purchased ~ .,
data = training_set,
type = "C-classification",
kernel = "radial")
# Predicción de los resulados con el Conjunto de Testing
y_pred = predict(classifier, newdata = testing_set[,-3])
# Crear la matriz de confusión
cm = table(testing_set[,3], y_pred)
# Aplicar el algoritmo de k-fold cross validation ++++++++++++++++++++++++++++++
library(caret)
folds = createFolds(training_set$Purchased, k = 10)
cv = lapply(folds, function(x) {
training_fold = training_set[-x, ]
test_fold = training_set[x, ]
classifier = svm(formula = Purchased ~ .,
data = training_fold,
type = "C-classification",
kernel = "radial")
y_pred = predict(classifier, newdata = test_fold[,-3])
cm = table(test_fold[,3], y_pred)
accuracy = (cm[1][1]+cm[2][2]) / (cm[1][1]+cm[1][2]+cm[2][1]+cm[2][2])
return(accuracy)
})
View(cv)
cv
# K-FOLD CROSS VALIDATION
# Importar el dataset
dataset <- read.csv('Social_Network_Ads.csv')
dataset <- dataset[, 3:5]
# Dividir los datos en training y testing
#install.packages("caTools")
library(caTools)
set.seed(123)
split <- sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
testing_set = subset(dataset, split == FALSE)
# Escalado de variables
training_set[,1:2] = scale(training_set[,1:2])
testing_set[,1:2] = scale(testing_set[,1:2])
# Ajustar el clasificador en el Conjunto de Entrenamiento
library(e1071)
classifier = svm(formula = Purchased ~ .,
data = training_set,
type = "C-classification",
kernel = "radial")
# Predicción de los resulados con el Conjunto de Testing
y_pred = predict(classifier, newdata = testing_set[,-3])
# Crear la matriz de confusión
cm = table(testing_set[,3], y_pred)
# Aplicar el algoritmo de k-fold cross validation ++++++++++++++++++++++++++++++
library(caret)
folds = createFolds(training_set$Purchased, k = 10)
cv = lapply(folds, function(x) {
training_fold = training_set[-x, ]
test_fold = training_set[x, ]
classifier = svm(formula = Purchased ~ .,
data = training_fold,
type = "C-classification",
kernel = "radial")
y_pred = predict(classifier, newdata = test_fold[,-3])
cm = table(test_fold[,3], y_pred)
accuracy = (cm[1,1]+cm[2,2]) / (cm[1,1]+cm[1,2]+cm[2,1]+cm[2,2])
return(accuracy)
})
View(cv)
cv
mean(cv)
mean(as.numeric(cv))
accuracy_sd = sd(as.numeric(cv))
accuracy_sd
setwd("C:/Machine Learning/machinelearning-az/datasets/Part 10 - Model Selection & Boosting/Section 48 - Model Selection")
setwd("C:/Machine Learning/machinelearning-az/datasets/Part 10 - Model Selection & Boosting/Section 48 - Model Selection")
# GRID SEARCH
# Importar el dataset
dataset <- read.csv('Social_Network_Ads.csv')
dataset <- dataset[, 3:5]
# Dividir los datos en training y testing
#install.packages("caTools")
library(caTools)
set.seed(123)
split <- sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
testing_set = subset(dataset, split == FALSE)
# Escalado de variables
training_set[,1:2] = scale(training_set[,1:2])
testing_set[,1:2] = scale(testing_set[,1:2])
# Ajustar el clasificador en el Conjunto de Entrenamiento
library(e1071)
classifier = svm(formula = Purchased ~ .,
data = training_set,
type = "C-classification",
kernel = "radial")
# Predicción de los resulados con el Conjunto de Testing
y_pred = predict(classifier, newdata = testing_set[,-3])
# Crear la matriz de confusión
cm = table(testing_set[,3], y_pred)
# Aplicar el algoritmo de k-fold cross validation
library(caret)
folds = createFolds(training_set$Purchased, k = 10)
cv = lapply(folds, function(x) {
training_fold = training_set[-x, ]
test_fold = training_set[x, ]
classifier = svm(formula = Purchased ~ .,
data = training_fold,
type = "C-classification",
kernel = "radial")
y_pred = predict(classifier, newdata = test_fold[,-3])
cm = table(test_fold[,3], y_pred)
accuracy = (cm[1,1]+cm[2,2]) / (cm[1,1]+cm[1,2]+cm[2,1]+cm[2,2])
return(accuracy)
})
accuracy = mean(as.numeric(cv))
accuracy_sd = sd(as.numeric(cv))
# Aplicar la mejora de Grid Search para optimizar el modelo y sus parametros +++
library(caret)
classifier = train(form = Purchased ~ .,
data = training_set,
method = 'svmRadial')
# Importar el dataset
dataset <- read.csv('Social_Network_Ads.csv')
dataset <- dataset[, 3:5]
dataset$Purchased <- factor(dataset$Purchased)
# Dividir los datos en training y testing
#install.packages("caTools")
library(caTools)
set.seed(123)
split <- sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
testing_set = subset(dataset, split == FALSE)
# Escalado de variables
training_set[,1:2] = scale(training_set[,1:2])
testing_set[,1:2] = scale(testing_set[,1:2])
# Ajustar el clasificador en el Conjunto de Entrenamiento
library(e1071)
classifier = svm(formula = Purchased ~ .,
data = training_set,
type = "C-classification",
kernel = "radial")
# Predicción de los resulados con el Conjunto de Testing
y_pred = predict(classifier, newdata = testing_set[,-3])
# Crear la matriz de confusión
cm = table(testing_set[,3], y_pred)
# Aplicar el algoritmo de k-fold cross validation
library(caret)
folds = createFolds(training_set$Purchased, k = 10)
cv = lapply(folds, function(x) {
training_fold = training_set[-x, ]
test_fold = training_set[x, ]
classifier = svm(formula = Purchased ~ .,
data = training_fold,
type = "C-classification",
kernel = "radial")
y_pred = predict(classifier, newdata = test_fold[,-3])
cm = table(test_fold[,3], y_pred)
accuracy = (cm[1,1]+cm[2,2]) / (cm[1,1]+cm[1,2]+cm[2,1]+cm[2,2])
return(accuracy)
})
accuracy = mean(as.numeric(cv))
accuracy_sd = sd(as.numeric(cv))
# Aplicar la mejora de Grid Search para optimizar el modelo y sus parametros +++
library(caret)
classifier = train(form = Purchased ~ .,
data = training_set,
method = 'svmRadial')
classifier
