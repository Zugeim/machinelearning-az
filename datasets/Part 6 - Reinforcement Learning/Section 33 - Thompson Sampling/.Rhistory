ad = 0
for (i in 1:d) {
if (number_of_selectios[i] > 0) {
average_reward = sums_of_rewards[i] / number_of_selectios[i]
delta_i = sqrt(3/2*log(n)/number_of_selectios[i])
upper_bound = average_reward + delta_i
}else{
upper_bound = 1e400
}
if(upper_bound > max_upper_bound){
max_upper_bound = upper_bound
ad = i
}
}
ads_selected = append(ads_selected, ad)
number_of_selectios[ad] = number_of_selectios[ad] + 1
reward = dataset[n, ad]
sums_of_rewards[ad] = sums_of_rewards[ad] + reward
total_reward = total_reward + reward
}
# Histograma de resultados
hist(ads_selected,
col = "lightblue",
main = "Histograma de los Anuncios",
xlab = "ID del Anuncio",
ylab = "Frecuencia absoluta del anuncio")
setwd("C:/Machine Learning/machinelearning-az/datasets/Part 6 - Reinforcement Learning/Section 33 - Thompson Sampling")
# Importar dataset
dataset = read.csv("Ads_CTR_Optimisation.csv")
# Implementar Muestreo De Thompson
d = 10
N = 10000
number_of_rewards_1 = integer(d)
number_of_rewards_0 = integer(d)
ads_selected = integer(0)
total_reward = 0
for (n in 1:N) {
max_random = 0
ad = 0
for (i in 1:d) {
random_beta = rbeta(n = 1,
shape1 = number_of_rewards_1[i]+1,
shape2 = number_of_rewards_0[i+1])
if(random_beta > max_random){
max_random = random_beta
ad = i
}
}
ads_selected = append(ads_selected, ad)
reward = dataset[n, ad]
if (reward == 1) {
number_of_rewards_1[ad] = number_of_rewards_1[ad] + 1
}else{
number_of_rewards_0[ad] = number_of_rewards_0[ad] + 1
}
total_reward = total_reward + reward
}
dataset = read.csv("Ads_CTR_Optimisation.csv")
# Implementar Muestreo De Thompson
d = 10
N = 10000
number_of_rewards_1 = integer(d)
number_of_rewards_0 = integer(d)
ads_selected = integer(0)
total_reward = 0
for (n in 1:N) {
max_random = 0
ad = 0
for (i in 1:d) {
random_beta = rbeta(n = 1,
shape1 = number_of_rewards_1[i]+1,
shape2 = number_of_rewards_0[i]+1)
if(random_beta > max_random){
max_random = random_beta
ad = i
}
}
ads_selected = append(ads_selected, ad)
reward = dataset[n, ad]
if (reward == 1) {
number_of_rewards_1[ad] = number_of_rewards_1[ad] + 1
}else{
number_of_rewards_0[ad] = number_of_rewards_0[ad] + 1
}
total_reward = total_reward + reward
}
# Implementar Muestreo De Thompson
d = 10
N = 10000
number_of_rewards_1 = integer(d)
number_of_rewards_0 = integer(d)
ads_selected = integer(0)
total_reward = 0
for (n in 1:N) {
max_random = 0
ad = 0
for (i in 1:d) {
random_beta = rbeta(n = 1,
shape1 = number_of_rewards_1[i]+1,
shape2 = number_of_rewards_0[i]+1)
if(random_beta > max_random){
max_random = random_beta
ad = i
}
}
ads_selected = append(ads_selected, ad)
reward = dataset[n, ad]
if (reward == 1) {
number_of_rewards_1[ad] = number_of_rewards_1[ad] + 1
}else{
number_of_rewards_0[ad] = number_of_rewards_0[ad] + 1
}
total_reward = total_reward + reward
}
# Implementar Muestreo De Thompson
d = 10
N = 10000
number_of_rewards_1 = integer(d)
number_of_rewards_0 = integer(d)
ads_selected = integer(0)
total_reward = 0
for (n in 1:N) {
max_random = 0
ad = 0
for (i in 1:d) {
random_beta = rbeta(n = 1,
shape1 = number_of_rewards_1[i]+1,
shape2 = number_of_rewards_0[i]+1)
if(random_beta > max_random){
max_random = random_beta
ad = i
}
}
ads_selected = append(ads_selected, ad)
reward = dataset[n, ad]
if (reward == 1) {
number_of_rewards_1[ad] = number_of_rewards_1[ad] + 1
}else{
number_of_rewards_0[ad] = number_of_rewards_0[ad] + 1
}
total_reward = total_reward + reward
}
# Implementar Muestreo De Thompson
d = 10
N = 10000
number_of_rewards_1 = integer(d)
number_of_rewards_0 = integer(d)
ads_selected = integer(0)
total_reward = 0
for (n in 1:N) {
max_random = 0
ad = 0
for (i in 1:d) {
random_beta = rbeta(n = 1,
shape1 = number_of_rewards_1[i]+1,
shape2 = number_of_rewards_0[i]+1)
if(random_beta > max_random){
max_random = random_beta
ad = i
}
}
ads_selected = append(ads_selected, ad)
reward = dataset[n, ad]
if (reward == 1) {
number_of_rewards_1[ad] = number_of_rewards_1[ad] + 1
}else{
number_of_rewards_0[ad] = number_of_rewards_0[ad] + 1
}
total_reward = total_reward + reward
}
# Implementar Muestreo De Thompson
d = 10
N = 10000
number_of_rewards_1 = integer(d)
number_of_rewards_0 = integer(d)
ads_selected = integer(0)
total_reward = 0
for (n in 1:N) {
max_random = 0
ad = 0
for (i in 1:d) {
random_beta = rbeta(n = 1,
shape1 = number_of_rewards_1[i]+1,
shape2 = number_of_rewards_0[i]+1)
if(random_beta > max_random){
max_random = random_beta
ad = i
}
}
ads_selected = append(ads_selected, ad)
reward = dataset[n, ad]
if (reward == 1) {
number_of_rewards_1[ad] = number_of_rewards_1[ad] + 1
}else{
number_of_rewards_0[ad] = number_of_rewards_0[ad] + 1
}
total_reward = total_reward + reward
}
# Implementar Muestreo De Thompson
d = 10
N = 10000
number_of_rewards_1 = integer(d)
number_of_rewards_0 = integer(d)
ads_selected = integer(0)
total_reward = 0
for (n in 1:N) {
max_random = 0
ad = 0
for (i in 1:d) {
random_beta = rbeta(n = 1,
shape1 = number_of_rewards_1[i]+1,
shape2 = number_of_rewards_0[i]+1)
if(random_beta > max_random){
max_random = random_beta
ad = i
}
}
ads_selected = append(ads_selected, ad)
reward = dataset[n, ad]
if (reward == 1) {
number_of_rewards_1[ad] = number_of_rewards_1[ad] + 1
}else{
number_of_rewards_0[ad] = number_of_rewards_0[ad] + 1
}
total_reward = total_reward + reward
}
# Implementar Muestreo De Thompson
d = 10
N = 10000
number_of_rewards_1 = integer(d)
number_of_rewards_0 = integer(d)
ads_selected = integer(0)
total_reward = 0
for (n in 1:N) {
max_random = 0
ad = 0
for (i in 1:d) {
random_beta = rbeta(n = 1,
shape1 = number_of_rewards_1[i]+1,
shape2 = number_of_rewards_0[i]+1)
if(random_beta > max_random){
max_random = random_beta
ad = i
}
}
ads_selected = append(ads_selected, ad)
reward = dataset[n, ad]
if (reward == 1) {
number_of_rewards_1[ad] = number_of_rewards_1[ad] + 1
}else{
number_of_rewards_0[ad] = number_of_rewards_0[ad] + 1
}
total_reward = total_reward + reward
}
# Implementar Muestreo De Thompson
d = 10
N = 10000
number_of_rewards_1 = integer(d)
number_of_rewards_0 = integer(d)
ads_selected = integer(0)
total_reward = 0
for (n in 1:N) {
max_random = 0
ad = 0
for (i in 1:d) {
random_beta = rbeta(n = 1,
shape1 = number_of_rewards_1[i]+1,
shape2 = number_of_rewards_0[i]+1)
if(random_beta > max_random){
max_random = random_beta
ad = i
}
}
ads_selected = append(ads_selected, ad)
reward = dataset[n, ad]
if (reward == 1) {
number_of_rewards_1[ad] = number_of_rewards_1[ad] + 1
}else{
number_of_rewards_0[ad] = number_of_rewards_0[ad] + 1
}
total_reward = total_reward + reward
}
# Implementar Muestreo De Thompson
d = 10
N = 10000
number_of_rewards_1 = integer(d)
number_of_rewards_0 = integer(d)
ads_selected = integer(0)
total_reward = 0
for (n in 1:N) {
max_random = 0
ad = 0
for (i in 1:d) {
random_beta = rbeta(n = 1,
shape1 = number_of_rewards_1[i]+1,
shape2 = number_of_rewards_0[i]+1)
if(random_beta > max_random){
max_random = random_beta
ad = i
}
}
ads_selected = append(ads_selected, ad)
reward = dataset[n, ad]
if (reward == 1) {
number_of_rewards_1[ad] = number_of_rewards_1[ad] + 1
}else{
number_of_rewards_0[ad] = number_of_rewards_0[ad] + 1
}
total_reward = total_reward + reward
}
# Implementar Muestreo De Thompson
d = 10
N = 10000
number_of_rewards_1 = integer(d)
number_of_rewards_0 = integer(d)
ads_selected = integer(0)
total_reward = 0
for (n in 1:N) {
max_random = 0
ad = 0
for (i in 1:d) {
random_beta = rbeta(n = 1,
shape1 = number_of_rewards_1[i]+1,
shape2 = number_of_rewards_0[i]+1)
if(random_beta > max_random){
max_random = random_beta
ad = i
}
}
ads_selected = append(ads_selected, ad)
reward = dataset[n, ad]
if (reward == 1) {
number_of_rewards_1[ad] = number_of_rewards_1[ad] + 1
}else{
number_of_rewards_0[ad] = number_of_rewards_0[ad] + 1
}
total_reward = total_reward + reward
}
# Implementar Muestreo De Thompson
d = 10
N = 10000
number_of_rewards_1 = integer(d)
number_of_rewards_0 = integer(d)
ads_selected = integer(0)
total_reward = 0
for (n in 1:N) {
max_random = 0
ad = 0
for (i in 1:d) {
random_beta = rbeta(n = 1,
shape1 = number_of_rewards_1[i]+1,
shape2 = number_of_rewards_0[i]+1)
if(random_beta > max_random){
max_random = random_beta
ad = i
}
}
ads_selected = append(ads_selected, ad)
reward = dataset[n, ad]
if (reward == 1) {
number_of_rewards_1[ad] = number_of_rewards_1[ad] + 1
}else{
number_of_rewards_0[ad] = number_of_rewards_0[ad] + 1
}
total_reward = total_reward + reward
}
# Implementar Muestreo De Thompson
d = 10
N = 10000
number_of_rewards_1 = integer(d)
number_of_rewards_0 = integer(d)
ads_selected = integer(0)
total_reward = 0
for (n in 1:N) {
max_random = 0
ad = 0
for (i in 1:d) {
random_beta = rbeta(n = 1,
shape1 = number_of_rewards_1[i]+1,
shape2 = number_of_rewards_0[i]+1)
if(random_beta > max_random){
max_random = random_beta
ad = i
}
}
ads_selected = append(ads_selected, ad)
reward = dataset[n, ad]
if (reward == 1) {
number_of_rewards_1[ad] = number_of_rewards_1[ad] + 1
}else{
number_of_rewards_0[ad] = number_of_rewards_0[ad] + 1
}
total_reward = total_reward + reward
}
# Implementar Muestreo De Thompson
d = 10
N = 10000
number_of_rewards_1 = integer(d)
number_of_rewards_0 = integer(d)
ads_selected = integer(0)
total_reward = 0
for (n in 1:N) {
max_random = 0
ad = 0
for (i in 1:d) {
random_beta = rbeta(n = 1,
shape1 = number_of_rewards_1[i]+1,
shape2 = number_of_rewards_0[i]+1)
if(random_beta > max_random){
max_random = random_beta
ad = i
}
}
ads_selected = append(ads_selected, ad)
reward = dataset[n, ad]
if (reward == 1) {
number_of_rewards_1[ad] = number_of_rewards_1[ad] + 1
}else{
number_of_rewards_0[ad] = number_of_rewards_0[ad] + 1
}
total_reward = total_reward + reward
}
# Implementar Muestreo De Thompson
d = 10
N = 10000
number_of_rewards_1 = integer(d)
number_of_rewards_0 = integer(d)
ads_selected = integer(0)
total_reward = 0
for (n in 1:N) {
max_random = 0
ad = 0
for (i in 1:d) {
random_beta = rbeta(n = 1,
shape1 = number_of_rewards_1[i]+1,
shape2 = number_of_rewards_0[i]+1)
if(random_beta > max_random){
max_random = random_beta
ad = i
}
}
ads_selected = append(ads_selected, ad)
reward = dataset[n, ad]
if (reward == 1) {
number_of_rewards_1[ad] = number_of_rewards_1[ad] + 1
}else{
number_of_rewards_0[ad] = number_of_rewards_0[ad] + 1
}
total_reward = total_reward + reward
}
# Implementar Muestreo De Thompson
d = 10
N = 10000
number_of_rewards_1 = integer(d)
number_of_rewards_0 = integer(d)
ads_selected = integer(0)
total_reward = 0
for (n in 1:N) {
max_random = 0
ad = 0
for (i in 1:d) {
random_beta = rbeta(n = 1,
shape1 = number_of_rewards_1[i]+1,
shape2 = number_of_rewards_0[i]+1)
if(random_beta > max_random){
max_random = random_beta
ad = i
}
}
ads_selected = append(ads_selected, ad)
reward = dataset[n, ad]
if (reward == 1) {
number_of_rewards_1[ad] = number_of_rewards_1[ad] + 1
}else{
number_of_rewards_0[ad] = number_of_rewards_0[ad] + 1
}
total_reward = total_reward + reward
}
# Implementar Muestreo De Thompson
d = 10
N = 10000
number_of_rewards_1 = integer(d)
number_of_rewards_0 = integer(d)
ads_selected = integer(0)
total_reward = 0
for (n in 1:N) {
max_random = 0
ad = 0
for (i in 1:d) {
random_beta = rbeta(n = 1,
shape1 = number_of_rewards_1[i]+1,
shape2 = number_of_rewards_0[i]+1)
if(random_beta > max_random){
max_random = random_beta
ad = i
}
}
ads_selected = append(ads_selected, ad)
reward = dataset[n, ad]
if (reward == 1) {
number_of_rewards_1[ad] = number_of_rewards_1[ad] + 1
}else{
number_of_rewards_0[ad] = number_of_rewards_0[ad] + 1
}
total_reward = total_reward + reward
}
# Histograma de resultados
hist(ads_selected,
col = "lightblue",
main = "Histograma de los Anuncios",
xlab = "ID del Anuncio",
ylab = "Frecuencia absoluta del anuncio")
