athlete <- as.factor(athlete)
data$athlete <- athlete
class(data$athlete)
female <- normalise(female)
female <- as.factor(female)
data$female <- female
class(data$female)
black <- normalise(black)
black <- as.factor(black)
data$black <- black
class(data$black)
white <- normalise(white)
white  <- as.factor(white)
data$white <- white
class(data$white)
class(sat)
summary(sat)
sat = as.numeric(sat)
data$sat <- sat
class(data$sat)
summary(data$sat)
head(data$sat)
class(tothrs)
head(tothrs)
tothrs <- gsub("h", "", tothrs)
tothrs <- as.numeric(tothrs)
class(tothrs)
summary(tothrs)
data$tothrs <- tothrs
head(data$tothrs)
class(colgpa)
head(colgpa)
summary(colgpa)
class(hsize)
head(hsize, 3)
grep(",", hsize)
hsize <- gsub(",",".",hsize)
grep(",",hsize)
hsize <- as.numeric(hsize)
data$hsize <- hsize
summary(hsize)
class(hsperc)
head(hsperc, 3)
summary(hsperc)
class(hsrank)
head(hsrank, 3)
summary(hsrank)
hsrank <- as.numeric(hsrank)
data$hsrank <- hsrank
class(data$hsrank)
summary(data$hsrank)
hsperc <- round(hsperc, 3)
data$hsperc <- hsperc
aux <- data[!is.na(hsize) & (round(hsrank/hsize, 3) != hsperc), c("hsrank", "hsize", "hsperc")]
data[!is.na(hsize) & (round(hsrank/hsize, 3) != hsperc), c("hsperc")] <- round((aux$hsrank/aux$hsize), 3)
hsperc <- data$hsperc
# Comprobación de si hay números mal.
sum(data[!is.na(hsize) & (round(hsrank/hsize, 3) != hsperc), c("hsize", "hsrank", "hsperc")])
head(data[,c("hsize", "hsrank", "hsperc")])
if(!require(ggplot2)){
install.packages('ggplot2',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(ggplot2)
}
ggplot(mapping = aes(x=sat))+ geom_density()
ggplot(mapping = aes(x=hsize))+ geom_density()
boxplot(sat, main = "sat")
boxplot(hsize, main = "hsize")
boxplot.stats(sat)$out -> outlier_values
li <- boxplot.stats(sat)$stats[1]
ls <- boxplot.stats(sat)$stats[5]
sat[sat > ls | sat < li] <- NA
data$sat <- sat
boxplot(data$sat, main = "sat")
boxplot.stats(hsize)$out -> outlier_values
ls <- boxplot.stats(hsize)$stats[5]
hsize[hsize > ls] <- NA
data$hsize <- hsize
boxplot(data$hsize, main = "hsize")
boxplot.stats(hsize)$out -> outlier_values
ls <- boxplot.stats(hsize)$stats[5]
hsize[hsize > ls] <- NA
data$hsize <- hsize
boxplot(data$hsize, main = "hsize")
boxplot.stats(hsize)$out -> outlier_values
ls <- boxplot.stats(hsize)$stats[5]
hsize[hsize > ls] <- NA
data$hsize <- hsize
boxplot(data$hsize, main = "hsize")
summary(data)
if(!require(VIM)){
install.packages('VIM',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(VIM)
}
library(VIM)
data <- kNN(data, k = 11)
data[data$hsize_imp == TRUE |
data$sat_imp == TRUE |
data$colgpa_imp == TRUE,c(1,2,3,4,5,6)]
summary(data[,c("sat", "hsize", "colgpa")])
sat <- data[,c("sat")]
hsize <- data[,c("hsize")]
colgpa <- data[,c("colgpa")]
gpaletter <- cut(colgpa, breaks = c(0, 1.5, 2.50, 3.5, 4), labels = c("D", "C", "B", "A"), include.lowest = TRUE, right = FALSE)
unique(gpaletter[colgpa < 1.50])
unique(gpaletter[colgpa >= 1.5 & colgpa < 2.5])
unique(gpaletter[colgpa >= 2.5 & colgpa < 3.5])
unique(gpaletter[colgpa >= 3.5 & colgpa <= 4])
data$gpaletter <- gpaletter
head(data[,c("gpaletter", "colgpa")])
barplot(prop.table(table(athlete)),
main = "Athletes",
col = c("orange", "blue"),
ylim= c(0,1),
ylab = "percentage of athletes")
ggplot(data =  data, aes(x=athlete, fill=female)) +
geom_bar(position = "fill") +
scale_fill_manual(values = c("orange", "blue"),
labels = c("Men", "Women"),
name = "Sex") +
ggtitle('Athletes en función del sexo') +
theme(panel.background = element_rect(fill = "transparent"),
plot.title = element_text(hjust = 0.5)) +
labs(y="percentage of men and women")
if(!require(modeest)){
install.packages('modeest',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(modeest)
}
library(modeest)
statTable <- function(x)
{
statistics <- cbind(mfv(x), mean(x), var(x), sd(x), t(quantile(x)))
return(statistics)
}
estadisticas <- apply(data[,c("sat", "tothrs", "hsize", "hsrank")],2,statTable)
rownames(estadisticas) <- c("moda", "media", "var", "desv.est", "min", "Q1", "Q2", "Q3", "max")
install.packages("printr", type = "source",
repos=c("http://yihui.name/xran"))
library(printr)
estadisticas
detach("package:printr", unload = TRUE)
hist(sat, main="Histograma de la nota de acceso",col="blue", xlim = c(600,1400))
ggplot(data =  data, aes(x=sat, fill=female)) +
geom_histogram(bins = 30) +
scale_fill_manual(values = c("orange", "blue"),
labels = c("Men", "Women"),
name = "Sex") +
ggtitle('sat en función del sexo') +
theme(plot.title = element_text(hjust = 0.5))
write.csv(data, file = "gpa_clean.csv" ,row.names = FALSE)
version
update.packages()
install.packages("DescTools", type="binary")
install.packages("DescTools", type="binary")
library(DescTools)
tinytex::reinstall_tinytex(repository = "illinois")
if(!require(RCurl)){
install.packages('RCurl',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(RCurl)
}
if(!require(data.table)){
install.packages('data.table',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(data.table)
}
if(!require(tidyr)){
install.packages('tidyr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(tidyr)
}
if(!require(ggplot2)){
install.packages('ggplot2',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(ggplot2)
}
if(!require(stringr)){
install.packages('stringr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(stringr)
}
if(!require(funModeling)){
install.packages('funModeling',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(funModeling)
}
if(!require(Hmisc)){install.packages('Hmisc',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(Hmisc)
}
if(!require(plyr)){install.packages('plyr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(plyr)
}
if(!require(car)){install.packages('car',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(car)
}
if(!require(ggpubr)){install.packages('ggpubr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(ggpubr)
}
if(!require(lsr)){install.packages('lsr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(lsr)
}
if(!require(DescTools)){install.packages('DescTools',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(DescTools)
}
if(!require(gridExtra)){
install.packages('gridextra',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(gridExtra)
}
if(!require(caret)){
install.packages('caret',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(caret)
}
if(!require(RCurl)){
install.packages('RCurl',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(RCurl)
}
if(!require(data.table)){
install.packages('data.table',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(data.table)
}
if(!require(tidyr)){
install.packages('tidyr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(tidyr)
}
if(!require(ggplot2)){
install.packages('ggplot2',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(ggplot2)
}
if(!require(stringr)){
install.packages('stringr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(stringr)
}
if(!require(funModeling)){
install.packages('funModeling',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(funModeling)
}
if(!require(Hmisc)){install.packages('Hmisc',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(Hmisc)
}
if(!require(plyr)){install.packages('plyr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(plyr)
}
if(!require(car)){install.packages('car',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(car)
}
if(!require(ggpubr)){install.packages('ggpubr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(ggpubr)
}
if(!require(lsr)){install.packages('lsr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(lsr)
}
if(!require(DescTools)){install.packages('DescTools',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(DescTools)
}
if(!require(gridExtra)){
install.packages('gridextra',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(gridExtra)
}
if(!require(caret)){
install.packages('caret',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(caret)
}
if(!require(RCurl)){
install.packages('RCurl',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(RCurl)
}
if(!require(data.table)){
install.packages('data.table',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(data.table)
}
if(!require(tidyr)){
install.packages('tidyr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(tidyr)
}
if(!require(ggplot2)){
install.packages('ggplot2',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(ggplot2)
}
if(!require(stringr)){
install.packages('stringr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(stringr)
}
if(!require(funModeling)){
install.packages('funModeling',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(funModeling)
}
if(!require(Hmisc)){install.packages('Hmisc',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(Hmisc)
}
if(!require(plyr)){install.packages('plyr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(plyr)
}
if(!require(car)){install.packages('car',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(car)
}
if(!require(ggpubr)){install.packages('ggpubr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(ggpubr)
}
if(!require(lsr)){install.packages('lsr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(lsr)
}
if(!require(DescTools)){install.packages('DescTools',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(DescTools)
}
if(!require(gridExtra)){
install.packages('gridextra',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(gridExtra)
}
if(!require(caret)){
install.packages('caret',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(caret)
}
if(!require(RCurl)){
install.packages('RCurl',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(RCurl)
}
if(!require(data.table)){
install.packages('data.table',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(data.table)
}
if(!require(tidyr)){
install.packages('tidyr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(tidyr)
}
if(!require(ggplot2)){
install.packages('ggplot2',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(ggplot2)
}
if(!require(stringr)){
install.packages('stringr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(stringr)
}
if(!require(funModeling)){
install.packages('funModeling',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(funModeling)
}
if(!require(Hmisc)){install.packages('Hmisc',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(Hmisc)
}
if(!require(plyr)){install.packages('plyr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(plyr)
}
if(!require(car)){install.packages('car',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(car)
}
if(!require(ggpubr)){install.packages('ggpubr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(ggpubr)
}
if(!require(lsr)){install.packages('lsr',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(lsr)
}
if(!require(DescTools)){install.packages('DescTools',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(DescTools)
}
if(!require(gridExtra)){
install.packages('gridextra',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(gridExtra)
}
if(!require(caret)){
install.packages('caret',dependencies =c("Depends","Imports"),repos='http://cran.es.r-project.org')
require(caret)
}
.libPaths()
print("Hello")
# Importar el dataset
dataset <- read.csv('Social_Network_Ads.csv')
setwd("C:/Machine Learning/machinelearning-az/datasets/Part 3 - Classification/Section 17 - Kernel SVM")
# Importar el dataset
dataset <- read.csv('Social_Network_Ads.csv')
dataset <- dataset[, 3:5]
# # Codificar las variables categóricas
# dataset$Level <- factor(dataset$Level,
#                         levels = c("1", "California", "Florida"),
#                         labels = c(1, 2, 3))
# Dividir los datos en training y testing
#install.packages("caTools")
library(caTools)
set.seed(123)
split <- sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
testing_set = subset(dataset, split == FALSE)
# Escalado de variables
training_set[,1:2] = scale(training_set[,1:2])
testing_set[,1:2] = scale(testing_set[,1:2])
View(testing_set)
View(training_set)
library(e1071)
classifier = svm(formula = Purchased ~ .,
data = training_set,
type = "C-classification",
kernel = "radial")
# Predicción de los resulados con el Conjunto de Testing
y_pred = predict(classifier, newdata = testing_set[,-3])
# Crear la matriz de confusión
cm = table(testing_set[,3], y_pred)
cm
# Visualización del Conjunto de Entrenamiento
#En el tema de regresión logística parte 5 explica como instalar la librería
library(ElemStatLearn)
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
y_grid = predict(classifier, newdata = grid_set)
plot(set[, -3],
main = 'SVM Kernel (Conjunto de Entrenamiento)',
xlab = 'Edad', ylab = 'Sueldo Estimado',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
setwd("C:/Machine Learning/machinelearning-az/datasets/Part 3 - Classification/Section 18 - Naive Bayes")
# Importar el dataset
dataset <- read.csv('Social_Network_Ads.csv')
dataset <- dataset[, 3:5]
# # Codificar las variables categóricas
# dataset$Level <- factor(dataset$Level,
#                         levels = c("1", "California", "Florida"),
#                         labels = c(1, 2, 3))
# Dividir los datos en training y testing
#install.packages("caTools")
library(caTools)
set.seed(123)
split <- sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
testing_set = subset(dataset, split == FALSE)
# Escalado de variables
training_set[,1:2] = scale(training_set[,1:2])
testing_set[,1:2] = scale(testing_set[,1:2])
library(e1071)
classifier = naiveBayes(x = training_set[,-3],
y = training_set$Purchased)
# Predicción de los resulados con el Conjunto de Testing
y_pred = predict(classifier, newdata = testing_set[,-3])
# Crear la matriz de confusión
cm = table(testing_set[,3], y_pred)
cm
# Importar el dataset
dataset <- read.csv('Social_Network_Ads.csv')
dataset <- dataset[, 3:5]
# Codificar las variables categóricas
dataset$Purchased <- factor(dataset$Purchased,
levels = c(0,1))
# Dividir los datos en training y testing
#install.packages("caTools")
library(caTools)
set.seed(123)
split <- sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
testing_set = subset(dataset, split == FALSE)
# Escalado de variables
training_set[,1:2] = scale(training_set[,1:2])
testing_set[,1:2] = scale(testing_set[,1:2])
# Ajustar el clasificador en el Conjunto de Entrenamiento
library(e1071)
classifier = naiveBayes(x = training_set[,-3],
y = training_set$Purchased)
# Predicción de los resulados con el Conjunto de Testing
y_pred = predict(classifier, newdata = testing_set[,-3])
# Crear la matriz de confusión
cm = table(testing_set[,3], y_pred)
y_pred
cm
library(ElemStatLearn)
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.1)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.1)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
y_grid = predict(classifier, newdata = grid_set)
plot(set[, -3],
main = 'Naive Bayes (Conjunto de Entrenamiento)',
xlab = 'Edad', ylab = 'Sueldo Estimado',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
library(ElemStatLearn)
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.05)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.05)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
y_grid = predict(classifier, newdata = grid_set)
plot(set[, -3],
main = 'Naive Bayes (Conjunto de Entrenamiento)',
xlab = 'Edad', ylab = 'Sueldo Estimado',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.02)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.02)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
y_grid = predict(classifier, newdata = grid_set)
plot(set[, -3],
main = 'Naive Bayes (Conjunto de Entrenamiento)',
xlab = 'Edad', ylab = 'Sueldo Estimado',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
library(ElemStatLearn)
set = testing_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.02)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.02)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
y_grid = predict(classifier, newdata = grid_set)
plot(set[, -3],
main = 'Naive Bayes (Conjunto de Testing)',
xlab = 'Edad', ylab = 'Sueldo Estimado',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
